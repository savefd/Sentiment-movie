{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Movie Reviews using\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Reviews dataset from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive:Negative plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenpos = sum(reviews['sentiment'] == 'positive')\n",
    "lenneg = sum(reviews['sentiment'] == 'negative')\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "labels = 'Positives', 'Negative'\n",
    "sizes = [lenpos, lenneg] \n",
    "explode = (0.05, 0.05)\n",
    "\n",
    "plt.pie(sizes, explode = explode, shadow = True ,labels=labels, startangle=90, autopct= '%.1f')\n",
    "\n",
    "plt.axis('equal')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "0. (split train/test)\n",
    "1. Remove HTML tags\n",
    "2. Remove stopwords\n",
    "3. Remove Punctuation\n",
    "4. Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['review'] = reviews['review'].apply(lambda x: re.sub(r'<.*?>', '', reviews['review'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = reviews.sample(frac = 0.7, random_state = 42)\n",
    "df_test = reviews.drop(index = df_train.index)\n",
    "\n",
    "x_train = df_train.drop('sentiment', axis = 1)\n",
    "x_test = df_test.drop('sentiment', axis = 1)\n",
    "y_train = df_train[['sentiment']]\n",
    "y_test = df_test[['sentiment']]\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frequency dictionary and feature extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    final_list = []\n",
    "    token = word_tokenize(text)\n",
    "    for word in token:\n",
    "        if (word not in stopwords.words('english') \\\n",
    "             and word not in string.punctuation\\\n",
    "             and word not in \" '', ' ', '  ' ,'s, `` A \"):\n",
    "            final_list.append(word)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_count(traindf, labeldf):\n",
    "    n = 0\n",
    "    freqdic = {}\n",
    "    for rev in traindf['review']:\n",
    "        tmp = process(rev)\n",
    "        for word in tmp:\n",
    "            if labeldf.reset_index()['sentiment'][n] == 'positive':\n",
    "                try:\n",
    "                    freqdic[(word, 1)] += 1\n",
    "                except:\n",
    "                    freqdic[(word, 1)] = 1\n",
    "            else:\n",
    "                try:\n",
    "                    freqdic[(word, 0)] += 1\n",
    "                except:\n",
    "                    freqdic[(word, 0)] = 1\n",
    "        n += 1\n",
    "    return freqdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeature(text, freqdic):\n",
    "    words = process(text)\n",
    "    x = np.zeros((1, 3)) \n",
    "    x[0,0] = 1\n",
    "    for word in word_l:\n",
    "        try:\n",
    "            x[0,1] += freqs[(word,1)]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            x[0,2] += freqs[(word,0)]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    f = 1 / (1 + np.exp(-z))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, iteration):\n",
    "    m = len(x)\n",
    "    for i in range(0, iteration):\n",
    "        z = np.dot(x, theta)\n",
    "        f = sigmoid(z)\n",
    "        #cost func\n",
    "        J = (-1/m) *(np.dot(np.transpose(y),np.log(f)) + np.dot(np.transpose(1-y),np.log(1-f)))\n",
    "        # update the weights theta\n",
    "        theta = theta-(alpha*(np.dot(np.transpose(x),(f-y))))/m\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_x, train_y, freqdic, theta, alpha, interation):\n",
    "    X = np.zeros((len(train_x), 3))\n",
    "    for i in range(len(train_x)):\n",
    "        x[i, :] = extract_features(train_x['review'][i], freqdic)\n",
    "    \n",
    "    enc = OrdinalEncoder()\n",
    "    Y = enc.fit_transform(train_y)\n",
    "    \n",
    "    J, theta = gradientDescent(X, Y, theta, alpha, iteration)\n",
    "    \n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictoin for one case\n",
    "def predict(text, freqdic, theta):\n",
    "    \n",
    "    x = extract_features(text, freqdic)\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc_test(test_x, test_y, freqdic, theta):\n",
    "    for text in test_x:\n",
    "        y_pred = predict(text, freqdic, theta)\n",
    "        if y_pred > 0.5:\n",
    "            y_hat.append(1.0)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "    \n",
    "    tmp = np.array(y_hat) == test_y.flatten()\n",
    "    acc = sum(tmp)/len(tmp)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dic = frequency_count(x_train, y_train)\n",
    "model = train_model(x_train, y_train,\n",
    "                    freqdic, np.zeros((3, 1)),\n",
    "                    1e-7, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc_test(x_test, \n",
    "               y_test,\n",
    "               freqdic,\n",
    "               theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
